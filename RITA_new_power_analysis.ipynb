{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "645a4fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from mne.time_frequency import tfr_multitaper\n",
    "from matplotlib.patches import Rectangle\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105b3b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/marijn1/Library/CloudStorage/Dropbox/DATA SCIENCE/GitHub/RITA-Project_forstudent/data/data\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/marijn1/Library/CloudStorage/Dropbox/DATA SCIENCE/GitHub/RITA-Project_forstudent/data/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m project_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(project_path)\n\u001b[0;32m----> 4\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(project_path) \u001b[38;5;66;03m# go to the data subdir\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConcatenated_events/without_excluded_part/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      6\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConcatenated_events/without_excluded_part/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/marijn1/Library/CloudStorage/Dropbox/DATA SCIENCE/GitHub/RITA-Project_forstudent/data/data'"
     ]
    }
   ],
   "source": [
    "# project variables\n",
    "project_path = os.path.join(os.getcwd(), \"data\")\n",
    "print(project_path)\n",
    "os.chdir(project_path) # go to the data subdir\n",
    "if not os.path.exists(\"Concatenated_events/without_excluded_part/\"):\n",
    "    os.makedirs(\"Concatenated_events/without_excluded_part/\")\n",
    "if not os.path.exists(\"Concatenated_events/Grand_Average_Excluded/\"):\n",
    "    os.makedirs(\"Concatenated_events/Grand_Average_Excluded/\")\n",
    "if not os.path.exists(\"Plots/Participants_per_Condition_Pz_Fz/\"):\n",
    "    os.makedirs(\"Plots/Participants_per_Condition_Pz_Fz/\")\n",
    "if not os.path.exists(\"Plots/Average_per_Channel_Comparison/First Epoch/\"):\n",
    "    os.makedirs(\"Plots/Average_per_Channel_Comparison/First Epoch/\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5bcd97-3e2a-40c2-a4fd-04cc4c68e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading all channels and subsets\n",
    "\n",
    "ch_rm = ['Fp1', 'Fpz', 'Fp2', 'AFz', 'AF3', 'AF7', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', \n",
    "         'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'O1', 'C5', \n",
    "         'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'O2', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'P7', \n",
    "         'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO3', 'POz', 'PO4', 'PO8']\n",
    "\n",
    "f_rm = ['Fp1', 'Fpz', 'Fp2', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8']\n",
    "\n",
    "c_rm = [\"C5\", 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6']\n",
    "\n",
    "p_rm = [\"P7\",  'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO3', 'POz', 'PO4', 'PO8']\n",
    "\n",
    "la_rm = [\"F1\", \"F3\", \"F5\", \"FC1\", \"FC3\", \"FC5\"]\n",
    "\n",
    "ra_rm = [\"F2\", \"F4\",\"F6\", \"FC2\", \"FC4\", \"FC6\"]\n",
    "\n",
    "lp_rm = [\"CP1\", \"CP3\", \"CP5\", \"P1\", \"P3\", \"P5\"]\n",
    "\n",
    "rp_rm = [\"CP2\", \"CP4\", \"CP6\", \"P2\", \"P4\", \"P6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac1cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mne_multitaper_concate(iStims, path, freqs, fmin, fmax, tmin, tmax):\n",
    "\n",
    "    '''\n",
    "    This function will concatenate all selected epoch files from all participants from the \n",
    "    conditions defined in iStims,\n",
    "    after concatenation, 1 AverageTFR Object is saved along with a npy array.\n",
    "    '''\n",
    "\n",
    "    n_cycles = freqs / 2.\n",
    "\n",
    "    sample_rate = 500\n",
    "    \n",
    "    all_epochs = []\n",
    "    file_list = []\n",
    "\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "\n",
    "    all_epochs = []\n",
    "    file_list = []\n",
    "    all_annotations = None\n",
    "    \n",
    "    \n",
    "        #For every participant the selected stimuli's epoch files are listed\n",
    "    for iStim in iStims:\n",
    "        for i in [1,2,6,8,9,10,11,12,13,14,16,18,21,23,28,30,32]: \n",
    "            dir_path = os.path.join(path, f\"RM{str(i).zfill(2)}/\")\n",
    "        \n",
    "            # Check if the directory exists before listing files\n",
    "            if os.path.exists(dir_path):\n",
    "                # List files in the directory and filter by the stimulus and file extension\n",
    "                file_list.extend([dir_path+f for f in os.listdir(dir_path) if iStim in f ])\n",
    "    \n",
    "    #listed epoch files are loaded\n",
    "    for file in file_list:\n",
    "        file_epoch = mne.read_epochs(file, verbose=False)\n",
    "        file_epoch.apply_baseline((-0.5, 0), verbose=False)\n",
    "        \n",
    "        \n",
    "        if file_epoch.annotations is not None:\n",
    "            if all_annotations is None:\n",
    "                all_annotations = file_epoch.annotations\n",
    "            else:\n",
    "                all_annotations += file_epoch.annotations\n",
    "                \n",
    "        \n",
    "        all_epochs.append(file_epoch)\n",
    "    # Concatenating epoch files\n",
    "    concatenated_epochs = mne.concatenate_epochs(all_epochs)\n",
    "   \n",
    "    if all_annotations is not None:\n",
    "        concatenated_epochs.set_annotations(all_annotations)\n",
    "\n",
    "    # power analysis:\n",
    "    power = concatenated_epochs.compute_tfr(method=\"multitaper\", freqs=freqs, n_cycles=n_cycles, decim=10, return_itc=False, average=True, picks=\"eeg\", n_jobs=-1)\n",
    "\n",
    "\n",
    "    \n",
    "    if path == \"RM_First_Epoch/RM/\":    \n",
    "        if iStims == [\"101\", \"103\",\"105\",\"107\"]:\n",
    "            cond = \"first_irr\"\n",
    "        elif iStims == [\"102\", \"104\",\"106\",\"108\"]:\n",
    "            cond = \"first_reg\"\n",
    "    if path == \"RM_Second_Epoch/RM/\":         \n",
    "        if iStims == [\"121\",\"122\",\"125\",\"126\"]:\n",
    "            cond = \"sec_subj\"\n",
    "        elif iStims == [\"123\",\"124\",\"127\",\"128\"]:\n",
    "            cond = \"sec_obj\"\n",
    "        elif iStims == [\"121\",\"123\",\"125\",\"127\"]:\n",
    "            cond = \"sec_irr\"\n",
    "        elif iStims == [\"122\",\"124\",\"126\",\"128\"]:\n",
    "            cond = \"sec_reg\"\n",
    "\n",
    "    #Saving AverageTFR objects as .h5\n",
    "    tfr_name = \"RM_\"+cond+\"-tfr.h5\"\n",
    "    os.chdir(\"Concatenated_events/Grand_Average_Excluded/\")\n",
    "    mne.time_frequency.write_tfrs(tfr_name, power, overwrite=True, verbose=True)\n",
    "    print(\"TFR file saved\")    \n",
    "    \n",
    "    # extract power values to NumPy array\n",
    "    final_array = power.crop(tmin = tmin, tmax = tmax, include_tmax = True).data # shape: chan x freq x time \n",
    "    #print(power.freqs) # debug step    \n",
    "\n",
    "    # Saving the NumPy array file on the local output:\n",
    "    file_name = \"RM_\"+cond+\".npy\"\n",
    "    print(\"Saving file {}\".format(file_name))\n",
    "    np.save(file_name, final_array)\n",
    "    print(\"NumPy array file saved\")\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Processed the file in {toc - tic:0.4f} seconds\")\n",
    "    os.chdir(project_path)\n",
    "\n",
    "    return power\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db5adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e84fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Appointing iStims to condition and epoch variable\n",
    "first_irr= [\"101\", \"103\",\"105\",\"107\"]\n",
    "first_reg = [\"102\", \"104\",\"106\",\"108\"]\n",
    "sec_sub = [\"121\",\"122\",\"125\",\"126\"]\n",
    "sec_obj = [\"123\",\"124\",\"127\",\"128\"]\n",
    "sec_irr = [\"121\",\"123\",\"125\",\"127\"]\n",
    "sec_reg = [\"122\",\"124\",\"126\",\"128\"]\n",
    "\n",
    "fmin = 2\n",
    "fmax = 60\n",
    "freqs = np.arange(fmin, fmax, 1.)\n",
    "tmin = -1\n",
    "tmax = 2.1\n",
    "\n",
    "# specifying the output returns an averageTFR object (average across events)\n",
    "rm_first_irr =  mne_multitaper_concate(first_irr, \"RM_First_Epoch/RM/\", freqs, fmin, fmax, tmin, tmax) # call to funciton above\n",
    "rm_first_reg =  mne_multitaper_concate(first_reg, \"RM_First_Epoch/RM/\", freqs, fmin, fmax, tmin, tmax) # call to funciton above\n",
    "rm_sec_sub =  mne_multitaper_concate(sec_sub, \"RM_Second_Epoch/RM/\", freqs, fmin, fmax, tmin, tmax) # call to funciton above\n",
    "rm_sec_obj =  mne_multitaper_concate(sec_obj, \"RM_Second_Epoch/RM/\", freqs, fmin, fmax, tmin, tmax) # call to funciton above\n",
    "rm_sec_irr =  mne_multitaper_concate(sec_irr, \"RM_Second_Epoch/RM/\", freqs, fmin, fmax, tmin, tmax) # call to funciton above\n",
    "rm_sec_reg =  mne_multitaper_concate(sec_reg, \"RM_Second_Epoch/RM/\", freqs, fmin, fmax, tmin, tmax) # call to funciton above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803232c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mne_multitaper_part(iStims, path, freqs, fmin, fmax, tmin, tmax):\n",
    "\n",
    "    '''\n",
    "    This function creates the AveragerTFR Object for selected\n",
    "    iStims per participant.\n",
    "    '''\n",
    "\n",
    "    n_cycles = freqs / 2.\n",
    "\n",
    "    sample_rate = 500\n",
    "    \n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "\n",
    "\n",
    "    \n",
    "    # Adding iStims events per participant in one list\n",
    "    for iPart in [1,2,6,8,9,10,11,12,13,14,16,18,21,23,28,30,32]:\n",
    "        all_epochs = []\n",
    "        file_list = []\n",
    "        all_annotations = None\n",
    "        dir_path = os.path.join(path, f\"RM{str(iPart).zfill(2)}/\")\n",
    "\n",
    "        for iStim in iStims:\n",
    "        \n",
    "            # Check if the directory exists before listing files\n",
    "            if os.path.exists(dir_path):\n",
    "                # List files in the directory and filter by the stimulus and file extension\n",
    "                file_list.extend([dir_path+f for f in os.listdir(dir_path) if iStim in f ])\n",
    "    \n",
    "        for file in file_list:\n",
    "            file_epoch = mne.read_epochs(file, verbose=False)\n",
    "            file_epoch.apply_baseline((-0.5, 0))\n",
    "\n",
    "            if file_epoch.annotations is not None:\n",
    "                if all_annotations is None:\n",
    "                    all_annotations = file_epoch.annotations\n",
    "                else:\n",
    "                    all_annotations += file_epoch.annotations\n",
    "                \n",
    "        \n",
    "            all_epochs.append(file_epoch)\n",
    "        \n",
    "        if all_epochs:\n",
    "            # Concatenating epoch files\n",
    "            concatenated_epochs = mne.concatenate_epochs(all_epochs)\n",
    "       \n",
    "            if all_annotations is not None:\n",
    "                concatenated_epochs.set_annotations(all_annotations)\n",
    "            \n",
    "            # power analysis:\n",
    "            power = concatenated_epochs.compute_tfr(method=\"multitaper\", freqs=freqs, n_cycles=n_cycles, decim=10, return_itc=False, average=True, picks=\"eeg\", n_jobs=-1)\n",
    "            \n",
    "    \n",
    "            if path == \"RM_First_Epoch/RM/\":    \n",
    "                if iStims == [\"101\", \"103\",\"105\",\"107\"]:\n",
    "                    cond = \"first_irr\"\n",
    "                elif iStims == [\"102\", \"104\",\"106\",\"108\"]:\n",
    "                    cond = \"first_reg\"\n",
    "            if path == \"RM_Second_Epoch/RM/\":         \n",
    "                if iStims == [\"121\",\"122\",\"125\",\"126\"]:\n",
    "                    cond = \"sec_subj\"\n",
    "                elif iStims == [\"123\",\"124\",\"127\",\"128\"]:\n",
    "                    cond = \"sec_obj\"\n",
    "                elif iStims == [\"121\",\"123\",\"125\",\"127\"]:\n",
    "                    cond = \"sec_irr\"\n",
    "                elif iStims == [\"122\",\"124\",\"126\",\"128\"]:\n",
    "                    cond = \"sec_reg\"\n",
    "        \n",
    "            if not os.path.exists(\"Concatenated_events/without_excluded_part/RM\"+str(iPart).zfill(2)):\n",
    "                os.makedirs(\"Concatenated_events/without_excluded_part/RM\"+str(iPart).zfill(2))\n",
    "    \n",
    "            tfr_name = \"RM\"+str(iPart).zfill(2)+\"_\"+cond+\"-tfr.h5\"\n",
    "            os.chdir(\"Concatenated_events/without_excluded_part/RM\"+str(iPart).zfill(2))\n",
    "            mne.time_frequency.write_tfrs(tfr_name, power, overwrite=True, verbose=True)\n",
    "            print(\"TFR file saved\")    \n",
    "            \n",
    "            # extract power values to NumPy array\n",
    "            final_array = power.crop(tmin = tmin, tmax = tmax, include_tmax = True).data # shape: chan x freq x time \n",
    "            #print(power.freqs) # debug step    \n",
    "    \n",
    "            # Saving the NumPy array file on the local output:\n",
    "            file_name = \"RM\"+str(iPart).zfill(2)+'_'+cond+\".npy\"\n",
    "            print(\"Saving file {}\".format(file_name))\n",
    "            np.save(file_name, final_array)\n",
    "            print(\"NumPy array file saved\")\n",
    "            toc = time.perf_counter()\n",
    "            print(f\"Processed the file in {toc - tic:0.4f} seconds\")\n",
    "            os.chdir(project_path)\n",
    "\n",
    "    return power\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efbd3eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "first_irr= [\"101\", \"103\",\"105\",\"107\"]\n",
    "first_reg = [\"102\", \"104\",\"106\",\"108\"]\n",
    "sec_sub = [\"121\",\"122\",\"125\",\"126\"]\n",
    "sec_obj = [\"123\",\"124\",\"127\",\"128\"]\n",
    "sec_irr = [\"121\",\"123\",\"125\",\"127\"]\n",
    "sec_reg = [\"122\",\"124\",\"126\",\"128\"]\n",
    "\n",
    "fmin = 2\n",
    "fmax = 60\n",
    "freqs = np.arange(fmin, fmax, 1.)\n",
    "tmin = -0.75\n",
    "tmax = 2\n",
    "\n",
    "rm_first_irr =  mne_multitaper_part(first_irr, \"RM_First_Epoch/RM/\", freqs, fmin, fmax, tmin, tmax)\n",
    "rm_first_reg =  mne_multitaper_part(first_reg, \"RM_First_Epoch/RM/\", freqs, fmin, fmax, tmin, tmax) \n",
    "rm_sec_sub =  mne_multitaper_part(sec_sub, \"RM_Second_Epoch/RM/\", freqs, fmin, fmax, tmin, tmax) \n",
    "rm_sec_obj =  mne_multitaper_part(sec_obj, \"RM_Second_Epoch/RM/\", freqs, fmin, fmax, tmin, tmax)\n",
    "rm_sec_irr =  mne_multitaper_part(sec_irr, \"RM_Second_Epoch/RM/\", freqs, fmin, fmax, tmin, tmax) \n",
    "rm_sec_reg =  mne_multitaper_part(sec_reg, \"RM_Second_Epoch/RM/\", freqs, fmin, fmax, tmin, tmax) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59642c45-b598-4e9e-a918-d9ed4e573966",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_1 = \"sec_reg\"\n",
    "cond_2 = \"sec_irr\"\n",
    "channels = [\"Pz\", \"Fz\"]\n",
    "os.chdir(project_path)\n",
    "for iPart in range(1,33):\n",
    "\n",
    "    if os.path.exists(f\"Concatenated_events/RM{str(iPart).zfill(2)}\"):\n",
    "        rm_1 = mne.time_frequency.read_tfrs(f\"Concatenated_events/RM{str(iPart).zfill(2)}/RM{str(iPart).zfill(2)}_{cond_1}-tfr.h5\")\n",
    "        rm_2 = mne.time_frequency.read_tfrs(f\"Concatenated_events/RM{str(iPart).zfill(2)}/RM{str(iPart).zfill(2)}_{cond_2}-tfr.h5\")\n",
    "\n",
    "        rm_1.apply_baseline(baseline=(-0.5, 0), mode=\"logratio\")\n",
    "        rm_2.apply_baseline(baseline=(-0.5, 0), mode=\"logratio\")\n",
    "        \n",
    "        tfr_list = [rm_1, rm_2]\n",
    "        max_val = max([tfr.data.max() for tfr in tfr_list])\n",
    "    \n",
    "        \n",
    "        for chan in channels:\n",
    "    \n",
    "            if not os.path.exists(\"Plots/Participants_per_Condition_Pz_Fz/RM\"+str(iPart).zfill(2)):\n",
    "                os.makedirs(\"Plots/Participants_per_Condition_Pz_Fz/RM\"+str(iPart).zfill(2))\n",
    "    \n",
    "            os.chdir(\"Plots/Participants_per_Condition_Pz_Fz/RM\"+str(iPart).zfill(2))\n",
    "            \n",
    "            \n",
    "            rm_1.plot(tmax = 2.1, vlim=(-0.35,0.35), picks=[chan], title=f\"RM{str(iPart).zfill(2)} - {cond_1} - {chan}\")[0].savefig(f\"RM{str(iPart).zfill(2)}_{cond_1}_{chan}.png\", dpi=300)\n",
    "            rm_2.plot(tmax = 2.1, vlim=(-0.35,0.35), picks=[chan], title=f\"RM{str(iPart).zfill(2)} - {cond_2} - {chan}\")[0].savefig(f\"RM{str(iPart).zfill(2)}_{cond_2}_{chan}.png\", dpi=300)\n",
    "    \n",
    "            os.chdir(project_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87372e-457c-42cc-a3bb-35f5d3ae97a5",
   "metadata": {},
   "source": [
    "# Average per Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e16c1-9b55-4619-9c4a-0bad2a00b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_1 = \"first_reg\"\n",
    "cond_2 = \"first_irr\"\n",
    "\n",
    "\n",
    "if os.path.exists(f\"Concatenated_events/Grand_Average_Excluded\"):\n",
    "    rm_1 = mne.time_frequency.read_tfrs(f\"Concatenated_events/Grand_Average_Excluded/RM_{cond_1}-tfr.h5\")\n",
    "    rm_2 = mne.time_frequency.read_tfrs(f\"Concatenated_events/Grand_Average_Excluded/RM_{cond_2}-tfr.h5\")\n",
    "    \n",
    "    for ch_index, ch_name in enumerate(ch_rm):\n",
    "        \n",
    "        # Create a single figure with 1 row and 2 columns\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "    \n",
    "        # Plot the first condition in the first subplot\n",
    "        rm_1.plot(picks=[ch_name], tmin=-0.75, tmax=2,vlim=(-0.35, 0.35), mode=\"logratio\", baseline=(-0.5, 0), axes=axes[0], colorbar=True, show=False, verbose=False)\n",
    "        axes[0].set_title(f\"Regular - {ch_name}\")\n",
    "        \n",
    "        # Plot the second condition in the second subplot\n",
    "        rm_2.plot(picks=[ch_name], tmin=-0.75, tmax=2, vlim=(-0.35, 0.35), mode=\"logratio\", baseline=(-0.5, 0), axes=axes[1], colorbar=True, show=False, verbose=False)\n",
    "        axes[1].set_title(f\"Irregular - {ch_name}\")\n",
    "\n",
    "        roi_params = [\n",
    "            ((0, 2), 0.5, 6, 'red'),   # roi_1\n",
    "            ((0.2, 9), 0.35, 7, 'black'),  # roi_2\n",
    "            ((1, 9), 0.5, 7, 'green'),  # roi_3\n",
    "            ((1, 9), 1, 7, 'blue'),    # roi_4\n",
    "        ]\n",
    "        \n",
    "        for ax in fig.axes:\n",
    "            for position, width, height, color in roi_params:\n",
    "                roi = Rectangle(position, width, height, \n",
    "                                linewidth=1, edgecolor=color, facecolor='none', linestyle='--')\n",
    "                ax.add_patch(roi)\n",
    "        \n",
    "        fig.suptitle(f\"Comparison {ch_name}\", fontsize=16)\n",
    "        fig.savefig(f\"Plots/Average_per_Channel_Comparison/First Epoch/{ch_name}.png\")\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd6d93-6924-4709-9afb-99f5cda62c5d",
   "metadata": {},
   "source": [
    "# Average per Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc6d5f-091a-49c7-8009-3417333606c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cond_1 = \"first_reg\"\n",
    "cond_2 = \"first_irr\"\n",
    "\n",
    "\n",
    "if os.path.exists(f\"Concatenated_events/Grand_Average_Excluded\"):\n",
    "    rm_1 = mne.time_frequency.read_tfrs(f\"Concatenated_events/Grand_Average_Excluded/RM_{cond_1}-tfr.h5\")\n",
    "    rm_2 = mne.time_frequency.read_tfrs(f\"Concatenated_events/Grand_Average_Excluded/RM_{cond_2}-tfr.h5\")\n",
    "    \n",
    "    for subset, subset_name in zip([f_rm, c_rm, p_rm, la_rm, lp_rm, ra_rm, rp_rm], [\"Frontal\", \"Central\", \"Parietal\", \"Left Anterior\", \"Left Posterior\", \"Right Anterior\", \"Right Posterior\"]):\n",
    "        \n",
    "        # Create a single figure with 1 row and 2 columns\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "    \n",
    "        # Plot the first condition in the first subplot\n",
    "        rm_1.plot(picks=subset, combine=\"mean\", tmin=-0.75, tmax=2,vlim=(-0.35, 0.35), mode=\"logratio\", baseline=(-0.5, 0), axes=axes[0], colorbar=True, show=False, verbose=False)\n",
    "        axes[0].set_title(f\"Regular - {subset_name}\")\n",
    "        \n",
    "        # Plot the second condition in the second subplot\n",
    "        rm_2.plot(picks=subset, combine=\"mean\", tmin=-0.75, tmax=2, vlim=(-0.35, 0.35), mode=\"logratio\", baseline=(-0.5, 0), axes=axes[1], colorbar=True, show=False, verbose=False)\n",
    "        axes[1].set_title(f\"Irregular - {subset_name}\")\n",
    "\n",
    "        roi_params = [\n",
    "            ((0, 2), 0.5, 6, 'red'),   # roi_1\n",
    "            ((0.2, 9), 0.35, 7, 'black'),  # roi_2\n",
    "            ((1, 9), 0.5, 7, 'green'),  # roi_3\n",
    "            ((1, 9), 1, 7, 'blue'),    # roi_4\n",
    "        ]\n",
    "        \n",
    "        for ax in fig.axes:\n",
    "            for position, width, height, color in roi_params:\n",
    "                roi = Rectangle(position, width, height, \n",
    "                                linewidth=1, edgecolor=color, facecolor='none', linestyle='--')\n",
    "                ax.add_patch(roi)\n",
    "        \n",
    "        fig.suptitle(f\"Comparison {subset_name}\", fontsize=16)\n",
    "        fig.savefig(f\"Plots/Average_per_Region/{subset_name}.png\")\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340cc539-cc0b-41c8-9513-fe9a5314587f",
   "metadata": {},
   "source": [
    "# Channel per Participant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06124b99-5012-4ec7-ba74-d08b6d9e1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_1 = \"first_reg\"\n",
    "cond_2 = \"first_irr\"\n",
    "\n",
    "for iPart in range(1,33):\n",
    "    if os.path.exists(f\"Concatenated_events/without_excluded_part/RM{str(iPart).zfill(2)}\"):\n",
    "        rm_1 = mne.time_frequency.read_tfrs(f\"Concatenated_events/without_excluded_part/RM{str(iPart).zfill(2)}/RM{str(iPart).zfill(2)}_{cond_1}-tfr.h5\")\n",
    "        rm_2 = mne.time_frequency.read_tfrs(f\"Concatenated_events/without_excluded_part/RM{str(iPart).zfill(2)}/RM{str(iPart).zfill(2)}_{cond_2}-tfr.h5\")\n",
    "               \n",
    "        for ch_index, ch_name in enumerate(ch_rm):\n",
    "\n",
    "            save_path = os.path.join(\"Plots/Chan_per_part/First Epoch\", f\"RM{str(iPart).zfill(2)}\")\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            \n",
    "            # Create a single figure with 1 row and 2 columns\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "        \n",
    "            # Plot the first condition in the first subplot\n",
    "            rm_1.plot(picks=ch_name, tmin=-0.75, tmax=2,vlim=(-0.35, 0.35), mode=\"logratio\", baseline=(-0.5, 0), axes=axes[0], colorbar=True, show=False, verbose=False)\n",
    "            axes[0].set_title(f\"Regular - {ch_name}\")\n",
    "            \n",
    "            # Plot the second condition in the second subplot\n",
    "            rm_2.plot(picks=ch_name, tmin=-0.75, tmax=2, vlim=(-0.35, 0.35), mode=\"logratio\", baseline=(-0.5, 0), axes=axes[1], colorbar=True, show=False, verbose=False)\n",
    "            axes[1].set_title(f\"Irregular - {ch_name}\")\n",
    "    \n",
    "            roi_params = [\n",
    "                ((0, 2), 0.5, 6, 'red'),   # roi_1\n",
    "                ((0.2, 9), 0.35, 6, 'black'),  # roi_2\n",
    "                ((1, 9), 0.5, 6, 'green'),  # roi_3\n",
    "                ((1, 9), 1, 6, 'blue'),    # roi_4\n",
    "            ]\n",
    "            \n",
    "            for ax in fig.axes:\n",
    "                for position, width, height, color in roi_params:\n",
    "                    roi = Rectangle(position, width, height, \n",
    "                                    linewidth=1, edgecolor=color, facecolor='none', linestyle='--')\n",
    "                    ax.add_patch(roi)\n",
    "            \n",
    "            fig.suptitle(f\"Comparison for RM{str(iPart).zfill(2)} {ch_name}\", fontsize=16)\n",
    "            fig.savefig(f\"Plots/Chan_per_part/First Epoch/RM{str(iPart).zfill(2)}/reg_irr_{ch_name}.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b23347-648c-4bcd-968a-d9d7b7c8f989",
   "metadata": {},
   "source": [
    "# Average of Subset of Channels per Particpant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c3a42e-5eb8-4152-a981-e100c06de6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_1 = \"first_reg\"\n",
    "cond_2 = \"first_irr\"\n",
    "\n",
    "for iPart in range(1,33):\n",
    "    if os.path.exists(f\"Concatenated_events/without_excluded_part/RM{str(iPart).zfill(2)}\"):\n",
    "        rm_1 = mne.time_frequency.read_tfrs(f\"Concatenated_events/without_excluded_part/RM{str(iPart).zfill(2)}/RM{str(iPart).zfill(2)}_{cond_1}-tfr.h5\")\n",
    "        rm_2 = mne.time_frequency.read_tfrs(f\"Concatenated_events/without_excluded_part/RM{str(iPart).zfill(2)}/RM{str(iPart).zfill(2)}_{cond_2}-tfr.h5\")\n",
    "\n",
    "        for subset, subset_name in zip([f_rm, c_rm, p_rm, la_rm, lp_rm, ra_rm, rp_rm], [\"Frontal\", \"Central\", \"Parietal\", \"Left Anterior\", \"Left Posterior\", \"Right Anterior\", \"Right Posterior\"]):\n",
    "       \n",
    "            \n",
    "            # Create a single figure with 1 row and 2 columns\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "        \n",
    "            # Plot the first condition in the first subplot\n",
    "            rm_1.plot(picks=subset, combine=\"mean\", tmin=-0.75, tmax=2,vlim=(-0.35, 0.35), mode=\"logratio\", baseline=(-0.5, 0), axes=axes[0], colorbar=True, show=False, verbose=False)\n",
    "            axes[0].set_title(f\"Regular - {subset_name}\")\n",
    "            \n",
    "            # Plot the second condition in the second subplot\n",
    "            rm_2.plot(picks=subset, combine=\"mean\", tmin=-0.75, tmax=2, vlim=(-0.35, 0.35), mode=\"logratio\", baseline=(-0.5, 0), axes=axes[1], colorbar=True, show=False, verbose=False)\n",
    "            axes[1].set_title(f\"Irregular - {subset_name}\")\n",
    "    \n",
    "            roi_params = [\n",
    "                ((0, 2), 0.5, 6, 'red'),   # roi_1\n",
    "                ((0.2, 9), 0.35, 6, 'black'),  # roi_2\n",
    "                ((1, 7), 0.5, 6, 'green'),  # roi_3\n",
    "                ((1, 7), 1, 6, 'blue'),    # roi_4\n",
    "            ]\n",
    "            \n",
    "            for ax in fig.axes:\n",
    "                for position, width, height, color in roi_params:\n",
    "                    roi = Rectangle(position, width, height, \n",
    "                                    linewidth=1, edgecolor=color, facecolor='none', linestyle='--')\n",
    "                    ax.add_patch(roi)\n",
    "            \n",
    "            fig.suptitle(f\"Comparison for RM{str(iPart).zfill(2)} {subset_name}\", fontsize=16)\n",
    "            fig.savefig(f\"Plots/Average_Chan_Subset_per_Part/RM{str(iPart).zfill(2)}_reg_irr_{subset_name}.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc337bbe-2781-4da3-bd05-35796f0f33a0",
   "metadata": {},
   "source": [
    "# Difference per Region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94d7dd-64b8-4b12-9c78-421ce237492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rm1 = mne.time_frequency.read_tfrs(f\"Concatenated_events/Grand_Average_Excluded/RM_first_irr-tfr.h5\")\n",
    "rm2 = mne.time_frequency.read_tfrs(f\"Concatenated_events/Grand_Average_Excluded/RM_first_reg-tfr.h5\")\n",
    "\n",
    "diff = rm2 -  rm1\n",
    "for subset, subset_name in zip([f_rm, c_rm, p_rm, la_rm, lp_rm, ra_rm, rp_rm], [\"Frontal\", \"Central\", \"Parietal\", \"Left Anterior\", \"Left Posterior\", \"Right Anterior\", \"Right Posterior\"]):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10,5))\n",
    "\n",
    "    diff.plot(axes=axes, picks=subset, title=f\"Difference Regular - Irregular for {subset_name} Region\", combine=\"mean\", tmin=-0.75, tmax=2, colorbar=True, show=False,verbose=False)\n",
    "\n",
    "    roi_params = [\n",
    "        ((0, 2), 0.5, 6, 'red'),   # roi_1\n",
    "        ((0.2, 9), 0.35, 7, 'black'),  # roi_2\n",
    "        ((1, 9), 0.5, 7, 'green'),  # roi_3\n",
    "        ((1, 9), 1, 7, 'blue'),    # roi_4\n",
    "    ]\n",
    "    \n",
    "    for ax in fig.axes:\n",
    "        for position, width, height, color in roi_params:\n",
    "            roi = Rectangle(position, width, height, \n",
    "                            linewidth=1, edgecolor=color, facecolor='none', linestyle='--')\n",
    "            ax.add_patch(roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0ac84-656a-4b27-91f6-296098669b6f",
   "metadata": {},
   "source": [
    "# Paired T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034d78c-dc8a-4bdd-9386-cadc82c41315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_tfr(channels, subset_name, roi_definitions, participants_range=range(1, 33)):\n",
    "    results = {}\n",
    "    cond_reg = \"first_reg\"\n",
    "    cond_irr = \"first_irr\"\n",
    "\n",
    "    for iPart in participants_range:\n",
    "        participant_name = f\"RM{str(iPart).zfill(2)}\"\n",
    "        participant_path = f\"Concatenated_events/without_excluded_part/{participant_name}\"\n",
    "        \n",
    "        \n",
    "        if os.path.exists(participant_path):\n",
    "            # Read the TFR data for both regular and irregular conditions\n",
    "            \n",
    "            rm_reg = mne.time_frequency.read_tfrs(f\"{participant_path}/{participant_name}_{cond_reg}-tfr.h5\", verbose=False)\n",
    "            rm_irr = mne.time_frequency.read_tfrs(f\"{participant_path}/{participant_name}_{cond_irr}-tfr.h5\", verbose=False)\n",
    "\n",
    "            # Select channels within the subset and average over the selected channels\n",
    "            \n",
    "            tfr_reg_subset = rm_reg.pick(picks=channels).data.mean(axis=0)\n",
    "            tfr_irr_subset = rm_irr.pick(picks=channels).data.mean(axis=0) \n",
    "    \n",
    "            for roi in roi_definitions:\n",
    "                \n",
    "                # Define masks to select specific time and frequency ranges for the regular condition\n",
    "                baseline_mask_reg = (rm_reg.times >= roi[\"baseline_time\"][0]) & (rm_reg.times <= roi[\"baseline_time\"][1])\n",
    "                time_mask_reg = (rm_reg.times >= roi[\"time_range\"][0]) & (rm_reg.times <= roi[\"time_range\"][1])\n",
    "                freq_mask_reg = (rm_reg.freqs >= roi[\"freq_range\"][0]) & (rm_reg.freqs <= roi[\"freq_range\"][1])\n",
    "    \n",
    "                # Define masks to select specific time and frequency ranges for the irregular condition\n",
    "                baseline_mask_irr = (rm_irr.times >= roi[\"baseline_time\"][0]) & (rm_irr.times <= roi[\"baseline_time\"][1])\n",
    "                time_mask_irr = (rm_irr.times >= roi[\"time_range\"][0]) & (rm_irr.times <= roi[\"time_range\"][1])\n",
    "                freq_mask_irr = (rm_irr.freqs >= roi[\"freq_range\"][0]) & (rm_irr.freqs <= roi[\"freq_range\"][1])\n",
    "    \n",
    "                # Calculate the average power within the time-frequency zone for each condition                \n",
    "                avg_tfr_baseline_reg = tfr_reg_subset[freq_mask_reg][:, baseline_mask_reg].mean() \n",
    "                avg_tfr_reg = tfr_reg_subset[freq_mask_reg][:, time_mask_reg].mean() \n",
    "    \n",
    "                avg_tfr_baseline_irr = tfr_irr_subset[freq_mask_irr][:, baseline_mask_irr].mean()  \n",
    "                avg_tfr_irr = tfr_irr_subset[freq_mask_irr][:, time_mask_irr].mean()  \n",
    "    \n",
    "                # Store results for paired t-test\n",
    "                if (subset_name, roi[\"name\"]) not in results:\n",
    "                    results[(subset_name, roi[\"name\"])] = {\"baseline_reg\": [], \"regular\": [], \"baseline_irr\": [], \"irregular\": []}\n",
    "                \n",
    "                # Append the calculated averages to the results dictionary\n",
    "                results[(subset_name, roi[\"name\"])]['baseline_reg'].append(avg_tfr_baseline_reg)                \n",
    "                results[(subset_name, roi[\"name\"])]['regular'].append(avg_tfr_reg)\n",
    "                results[(subset_name, roi[\"name\"])]['baseline_irr'].append(avg_tfr_baseline_irr)\n",
    "                results[(subset_name, roi[\"name\"])]['irregular'].append(avg_tfr_irr)\n",
    "\n",
    "    # Perform paired t-tests for each subset and ROI\n",
    "    for key, value in results.items():\n",
    "        subset_name, roi_name = key\n",
    "\n",
    "        \n",
    "        # Paired t-test between baseline and experimental condition for regular\n",
    "        t_stat_reg, p_value_reg = stats.ttest_rel(value[\"baseline_reg\"], value[\"regular\"])\n",
    "        \n",
    "        # Paired t-test between baseline and experimental condition for irregular\n",
    "        t_stat_irr, p_value_irr = stats.ttest_rel(value[\"baseline_irr\"], value[\"irregular\"])\n",
    "        \n",
    "        # Paired t-test between regular and irregular conditions (regardless of baseline)\n",
    "        t_stat_cond, p_value_cond = stats.ttest_rel(value[\"regular\"], value[\"irregular\"])\n",
    "\n",
    "        # Print the results of the t-tests\n",
    "        print(f\"{subset_name} - {roi_name}:\")\n",
    "        print(f\"  Baseline vs Regular: T-statistic: {t_stat_reg}, p-value: {p_value_reg}\")\n",
    "        print(f\"  Baseline vs Irregular: T-statistic: {t_stat_irr}, p-value: {p_value_irr}\")\n",
    "        print(f\"  Regular vs Irregular: T-statistic: {t_stat_cond}, p-value: {p_value_cond}\")\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c37a4b7-0601-4e73-a7a3-74d6f4f45b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_reg = \"first_reg\"\n",
    "cond_irr = \"first_irr\"\n",
    "\n",
    "#Define ROIs\n",
    "roi_definitions = [\n",
    "    {\"baseline_time\": (-0.3, -0.2), \"time_range\": (0, 0.5), \"freq_range\": (2, 8), \"name\": \"ROI 1\"},\n",
    "    {\"baseline_time\": (-0.3, -0.2), \"time_range\": (0.2, 0.55), \"freq_range\": (9, 16), \"name\": \"ROI 2\"},\n",
    "    {\"baseline_time\": (-0.3, -0.2), \"time_range\": (1.0, 1.5), \"freq_range\": (7, 13), \"name\": \"ROI 3\"},\n",
    "    {\"baseline_time\": (-0.3, -0.2), \"time_range\": (1.0, 2.0), \"freq_range\": (7, 13), \"name\": \"ROI 4\"}\n",
    "]\n",
    "\n",
    "analyze_tfr(f_rm, \"Frontal\", roi_definitions)\n",
    "analyze_tfr(p_rm, \"Parietal\", roi_definitions)\n",
    "analyze_tfr(c_rm, \"Central\", roi_definitions)\n",
    "analyze_tfr(la_rm, \"Left Anterior\", roi_definitions)\n",
    "analyze_tfr(ra_rm, \"Right Anterior\", roi_definitions)\n",
    "analyze_tfr(lp_rm, \"Left Posterior\", roi_definitions)\n",
    "analyze_tfr(rp_rm, \"Right Posterior\", roi_definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2498c6-60e6-45e1-becb-052070d7f269",
   "metadata": {},
   "source": [
    "# Mixed-effects model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ab67c-c6cd-44ce-b4bf-64306af75ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def prepare_data(channels, subset_name, roi_definitions, participants_range=range(1, 33)):\n",
    "    \"\"\"Prepare the data for mixed-effects modeling.\"\"\"\n",
    "    data = []\n",
    "    cond_reg = \"first_reg\"\n",
    "    cond_irr = \"first_irr\"\n",
    "\n",
    "    for iPart in participants_range:\n",
    "        participant_name = f\"RM{str(iPart).zfill(2)}\"\n",
    "        participant_path = f\"Concatenated_events/without_excluded_part/{participant_name}\"\n",
    "        \n",
    "        if os.path.exists(participant_path):\n",
    "            # Read the TFR data for both regular and irregular conditions\n",
    "            rm_reg = mne.time_frequency.read_tfrs(f\"{participant_path}/{participant_name}_{cond_reg}-tfr.h5\", verbose=False)\n",
    "            rm_irr = mne.time_frequency.read_tfrs(f\"{participant_path}/{participant_name}_{cond_irr}-tfr.h5\", verbose=False)\n",
    "\n",
    "            # Select channels within the subset and average over the selected channels\n",
    "            tfr_reg_subset = rm_reg.pick(picks=channels).data.mean(axis=0)\n",
    "            tfr_irr_subset = rm_irr.pick(picks=channels).data.mean(axis=0)\n",
    "    \n",
    "            for roi in roi_definitions:\n",
    "                # Define masks for time and frequency ranges\n",
    "                baseline_mask_reg = (rm_reg.times >= roi[\"baseline_time\"][0]) & (rm_reg.times <= roi[\"baseline_time\"][1])\n",
    "                time_mask_reg = (rm_reg.times >= roi[\"time_range\"][0]) & (rm_reg.times <= roi[\"time_range\"][1])\n",
    "                freq_mask_reg = (rm_reg.freqs >= roi[\"freq_range\"][0]) & (rm_reg.freqs <= roi[\"freq_range\"][1])\n",
    "\n",
    "                baseline_mask_irr = (rm_irr.times >= roi[\"baseline_time\"][0]) & (rm_irr.times <= roi[\"baseline_time\"][1])\n",
    "                time_mask_irr = (rm_irr.times >= roi[\"time_range\"][0]) & (rm_irr.times <= roi[\"time_range\"][1])\n",
    "                freq_mask_irr = (rm_irr.freqs >= roi[\"freq_range\"][0]) & (rm_irr.freqs <= roi[\"freq_range\"][1])\n",
    "\n",
    "                # Compute averages\n",
    "                avg_baseline_reg = tfr_reg_subset[freq_mask_reg][:, baseline_mask_reg].mean()\n",
    "                avg_reg = tfr_reg_subset[freq_mask_reg][:, time_mask_reg].mean()\n",
    "                avg_baseline_irr = tfr_irr_subset[freq_mask_irr][:, baseline_mask_irr].mean()\n",
    "                avg_irr = tfr_irr_subset[freq_mask_irr][:, time_mask_irr].mean()\n",
    "\n",
    "                # Append data for each condition\n",
    "                data.extend([\n",
    "                    {\"Participant\": participant_name, \"Condition\": \"Baseline\", \"Region\": subset_name, \"Power\": avg_baseline_reg, \"ROI\": roi[\"name\"], \"Hemisphere\": \"Both\"},\n",
    "                    {\"Participant\": participant_name, \"Condition\": \"Regular\", \"Region\": subset_name, \"Power\": avg_reg, \"ROI\": roi[\"name\"], \"Hemisphere\": \"Both\"},\n",
    "                    {\"Participant\": participant_name, \"Condition\": \"Baseline\", \"Region\": subset_name, \"Power\": avg_baseline_irr, \"ROI\": roi[\"name\"], \"Hemisphere\": \"Both\"},\n",
    "                    {\"Participant\": participant_name, \"Condition\": \"Irregular\", \"Region\": subset_name, \"Power\": avg_irr, \"ROI\": roi[\"name\"], \"Hemisphere\": \"Both\"},\n",
    "                ])\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Define ROIs\n",
    "roi_definitions = [\n",
    "    {\"baseline_time\": (-0.3, -0.2), \"time_range\": (0, 0.5), \"freq_range\": (2, 8), \"name\": \"ROI 1\"},\n",
    "    {\"baseline_time\": (-0.3, -0.2), \"time_range\": (0.2, 0.55), \"freq_range\": (9, 16), \"name\": \"ROI 2\"},\n",
    "    {\"baseline_time\": (-0.3, -0.2), \"time_range\": (1.0, 1.5), \"freq_range\": (7, 13), \"name\": \"ROI 3\"},\n",
    "    {\"baseline_time\": (-0.3, -0.2), \"time_range\": (1.0, 2.0), \"freq_range\": (7, 13), \"name\": \"ROI 4\"}\n",
    "]\n",
    "\n",
    "# Prepare the data\n",
    "data_frontal = prepare_data(f_rm, \"Frontal\", roi_definitions)\n",
    "data_parietal = prepare_data(p_rm, \"Parietal\", roi_definitions)\n",
    "data_central = prepare_data(c_rm, \"Central\", roi_definitions)\n",
    "\n",
    "# Combine all data\n",
    "all_data = pd.concat([data_frontal, data_parietal, data_central])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a0f6f-39ba-4518-9788-b3a6d22c63d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "def pairwise_comparisons(data):\n",
    "    \"\"\"\n",
    "    Perform pairwise comparisons for Baseline vs Regular, Baseline vs Irregular, \n",
    "    and Regular vs Irregular within each ROI and region, with FDR correction.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for roi in data[\"ROI\"].unique():\n",
    "        for region in data[\"Region\"].unique():\n",
    "            # Subset data for the current ROI and region\n",
    "            subset_data = data[(data[\"ROI\"] == roi) & (data[\"Region\"] == region)]\n",
    "            \n",
    "            print(f\"\\nPerforming pairwise comparisons for ROI {roi} in Region {region}...\")\n",
    "            \n",
    "            # Pairwise comparisons\n",
    "            comparisons = [\n",
    "                (\"Baseline\", \"Regular\"),\n",
    "                (\"Baseline\", \"Irregular\"),\n",
    "                (\"Regular\", \"Irregular\")\n",
    "            ]\n",
    "            \n",
    "            for condition1, condition2 in comparisons:\n",
    "                # Subset data for the two conditions\n",
    "                pair_data = subset_data[subset_data[\"Condition\"].isin([condition1, condition2])]\n",
    "                \n",
    "                if len(pair_data) < 3:\n",
    "                    print(f\"Skipping comparison {condition1} vs {condition2} for ROI {roi}, Region {region} due to insufficient data.\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Mixed-effects model for pairwise comparison\n",
    "                    model = smf.mixedlm(\"Power ~ Condition\", pair_data, groups=pair_data[\"Participant\"])\n",
    "                    result = model.fit(reml=True, method='lbfgs')\n",
    "                    \n",
    "                    # Extract parameter names dynamically\n",
    "                    param_name = f\"Condition[T.{condition2}]\"\n",
    "                    coef = result.params.get(param_name, np.nan)\n",
    "                    pval = result.pvalues.get(param_name, np.nan)\n",
    "                    \n",
    "                    # Store results\n",
    "                    results.append({\n",
    "                        \"ROI\": roi,\n",
    "                        \"Region\": region,\n",
    "                        \"Comparison\": f\"{condition1} vs {condition2}\",\n",
    "                        \"Coef\": coef,\n",
    "                        \"P-Value\": pval\n",
    "                    })\n",
    "                    \n",
    "                    # Print summary\n",
    "                    print(f\"Comparison {condition1} vs {condition2}:\")\n",
    "                    print(result.summary())\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fitting model for comparison {condition1} vs {condition2} in ROI {roi}, Region {region}: {e}\")\n",
    "    \n",
    "    # Convert results to a DataFrame for easier interpretation\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Apply FDR correction to P-Values\n",
    "    if not results_df.empty:\n",
    "        valid_pvals_idx = results_df[\"P-Value\"].notna()\n",
    "        p_values = results_df.loc[valid_pvals_idx, \"P-Value\"].values\n",
    "        _, corrected_p_values, _, _ = multipletests(p_values, method=\"fdr_bh\")\n",
    "        \n",
    "        # Update only rows with valid p-values\n",
    "        results_df.loc[valid_pvals_idx, \"Corrected P-Value\"] = corrected_p_values\n",
    "    else:\n",
    "        results_df[\"Corrected P-Value\"] = None\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Example: Assuming 'all_data' is your combined DataFrame\n",
    "results_df = pairwise_comparisons(all_data)\n",
    "\n",
    "# Save or display results\n",
    "print(results_df)\n",
    "results_df.to_csv(\"pairwise_comparisons_results_corrected.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RITA_anna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
